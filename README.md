Facial Emotion Recognition
Ce projet utilise un modÃ¨le d'apprentissage profond pour dÃ©tecter les Ã©motions faciales en temps rÃ©el Ã  partir de la vidÃ©o capturÃ©e par une webcam. L'application repose sur OpenCV pour le traitement d'image et un modÃ¨le prÃ©-entraÃ®nÃ© pour la classification des Ã©motions.

FonctionnalitÃ©s
âœ… DÃ©tection en temps rÃ©el : Capture les visages via webcam et dÃ©tecte les Ã©motions en direct.
âœ… ModÃ¨le prÃ©-entraÃ®nÃ© : Chargement via fichiers JSON et HDF5.
âœ… PrÃ©diction d'Ã©motions : Classe les Ã©motions en 7 catÃ©gories :
Neutre
Joie
Surprise
Tristesse
ColÃ¨re
DÃ©goÃ»t
Peur
âœ… Interface visuelle : Affiche le visage dÃ©tectÃ© et l'Ã©motion correspondante sur la vidÃ©o en direct.
PrÃ©requis
ğŸ“Œ Python 3.x
ğŸ“Œ OpenCV
ğŸ“Œ Keras
ğŸ“Œ TensorFlow
ğŸ“Œ NumPy
Installation
1ï¸âƒ£ Clonez ce repository :

git clone https://github.com/Abderraouf-Naji/facial-emotion-recognition.git
2ï¸âƒ£ Installez les dÃ©pendances :
pip install -r requirements.txt
3ï¸âƒ£ TÃ©lÃ©chargez les fichiers nÃ©cessaires :
ModÃ¨le JSON : fer1.json
Poids du modÃ¨le : fer1.h5
Classifieur Haar : haarcascade_frontalface_default.xml
Utilisation
Placez les fichiers JSON, HDF5, et Haar dans le dossier du projet.
ExÃ©cutez le script principal :
bash
Copier le code
python facial_emotion_recognition.py
Une fenÃªtre affichera la vidÃ©o capturÃ©e par la webcam avec les Ã©motions dÃ©tectÃ©es en temps rÃ©el.
Exemples d'applications
ğŸ¯ Analyse des Ã©motions dans les interactions humaines.
ğŸ¯ Ã‰tudes comportementales et psychologiques.
ğŸ¯ IntÃ©gration dans des systÃ¨mes interactifs ou des jeux.
Contribution
ğŸ’¡ Les contributions sont les bienvenues !

Ouvrez une issue pour signaler un bug ou proposer une amÃ©lioration.
Soumettez une pull request avec vos modifications.
Licence
ğŸ“œ Ce projet est sous licence MIT.
